{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8539ed72-3a8e-405b-b3d2-84a6a576964f",
   "metadata": {},
   "source": [
    "Notebook to quick test my masked conv implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "657bd6fa-7761-4ec2-a994-843d4431cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixelrnn.models as models\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e88d4b2-9a75-4758-9967-c273b2719284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaskedConv2d(3, 15, kernel_size=(7, 7), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "mconv = models.MaskedConv2d(3, 15, kernel_size=7)\n",
    "print(mconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e68ea43-d3b2-494e-8d17-0bf39c94afba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 3, 7, 7])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconv.mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4161e4e7-3b7c-4412-a3a5-c2a76b6fe200",
   "metadata": {},
   "source": [
    "Each input channel has associated 5 output channels, which will be used to predict the color values in the final stage\n",
    "\n",
    "here 15 is the value of _h_ in the paper.\n",
    "\n",
    "therefore, the first 5 output channels should only focus on the context, the next 5 channels shouild focus on the contexts\n",
    "plus the firs in channel (red) and the last 5 channels should see the first and second channel (red, green) but not the last (blue)\n",
    "\n",
    "notice the central value of the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3fa0111-2afd-4ca5-b536-597c16f784f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconv.mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4838200-c5ec-4c2e-9181-2c3e80e66c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconv.mask[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e397879f-8264-4964-84c1-617a358055fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconv.mask[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0755c425-a848-46bc-b3f5-5ef07d800111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0042,  0.0086,  0.0807, -0.0547,  0.0423,  0.0388,  0.0542],\n",
       "         [ 0.0123,  0.0490,  0.0398,  0.0222, -0.0386,  0.0685, -0.0526],\n",
       "         [ 0.0064,  0.0280,  0.0002,  0.0228, -0.0266, -0.0634, -0.0073],\n",
       "         [ 0.0585, -0.0417, -0.0669, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0302,  0.0322, -0.0413, -0.0755,  0.0048, -0.0168,  0.0444],\n",
       "         [-0.0567, -0.0455, -0.0377,  0.0726,  0.0491,  0.0387,  0.0052],\n",
       "         [-0.0450, -0.0515, -0.0083, -0.0762,  0.0587,  0.0738, -0.0713],\n",
       "         [ 0.0368, -0.0111, -0.0277, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0383, -0.0546,  0.0165, -0.0673, -0.0093,  0.0823,  0.0425],\n",
       "         [ 0.0215,  0.0610, -0.0245, -0.0370, -0.0695, -0.0696,  0.0736],\n",
       "         [-0.0424,  0.0189, -0.0639, -0.0744, -0.0103, -0.0078, -0.0696],\n",
       "         [-0.0507, -0.0553,  0.0046, -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconv.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4f44c16-7ef2-4728-a639-e5ec17a51c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconv.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb5018e6-0388-4e85-be21-dafc37ce4709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconv.weight.grad == None and mconv.weight.grad_fn == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18301840-9434-454b-bec1-800623737678",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mconv(torch.rand(3, 16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "242a40f7-ade2-49e4-820e-e85a412ab42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85641147-32db-4e48-ac39-3698a6c75aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = out.sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12802de3-bc5d-44aa-be98-e6657f4f75b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[52.3064, 52.2874, 53.2236, 54.3701, 52.2719, 51.0724, 52.2985],\n",
       "         [52.8811, 52.0356, 53.7780, 54.5993, 52.5928, 52.7514, 54.8170],\n",
       "         [54.1581, 53.0805, 54.7686, 55.3726, 54.5265, 54.8130, 56.0861],\n",
       "         [55.6373, 53.0983, 53.5719,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[50.5509, 49.4235, 49.0846, 49.9353, 49.0742, 48.6609, 49.4021],\n",
       "         [51.5525, 50.6719, 50.5354, 50.9387, 50.9939, 50.3543, 50.6520],\n",
       "         [50.4905, 48.9948, 48.4662, 49.2351, 49.1483, 48.6829, 48.8978],\n",
       "         [50.9918, 50.9123, 50.2490,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[52.1224, 50.2114, 49.4753, 49.8368, 51.7170, 49.4936, 49.9403],\n",
       "         [51.3126, 50.0306, 49.0712, 48.7779, 49.8772, 47.7623, 47.9266],\n",
       "         [51.5063, 50.4188, 48.5786, 48.9235, 50.7717, 48.8817, 49.0859],\n",
       "         [53.1644, 52.0146, 50.4344,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconv.weight.grad[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ff88c-ad75-4386-87c7-43798b3a061c",
   "metadata": {},
   "source": [
    "test single channel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17785439-315b-4dff-add1-8c49100ded47",
   "metadata": {},
   "outputs": [],
   "source": [
    "mconv = models.MaskedConv2d(1, 8, kernel_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "879b151a-881b-41fc-a284-b292bfd8e2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 7, 7])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5aa28fb-8fe8-497c-b9ef-bb34727a80d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 10])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mconv(torch.rand(1, 16, 16))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86a9c002-c5d4-4124-8975-10b531021026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconv.weight.shape == mconv.mask.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
